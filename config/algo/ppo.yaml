# defaults:
#- policy: ppo
#- optim: base

name: "ppo"

gamma: 0.99
gae_lambda: 0.95
ent_coef: 0.01
vf_coef: 0.5

batch_size: 32
n_steps: 2048

stats_window_size: 10 # was 100 ... for logging only
seed: 0


use_original_space: False
warmup_zero_action: False
